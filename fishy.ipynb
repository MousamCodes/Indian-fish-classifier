{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-09-01T01:50:06.524328Z","iopub.status.busy":"2022-09-01T01:50:06.522993Z","iopub.status.idle":"2022-09-01T01:50:07.320874Z","shell.execute_reply":"2022-09-01T01:50:07.319492Z","shell.execute_reply.started":"2022-09-01T01:50:06.52421Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import cv2, os, shutil, re, math\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from keras.preprocessing.image import ImageDataGenerator\n","import numpy as np\n","from keras.layers import *"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-01T02:24:55.07513Z","iopub.status.busy":"2022-09-01T02:24:55.074196Z","iopub.status.idle":"2022-09-01T02:24:55.294713Z","shell.execute_reply":"2022-09-01T02:24:55.293648Z","shell.execute_reply.started":"2022-09-01T02:24:55.075083Z"},"trusted":true},"outputs":[],"source":["df = pd.DataFrame()\n","filepaths = []\n","labels = []\n","\n","train_filepath = [i for i in os.listdir('/kaggle/input/fishes-species-in-the-indian-subcontinent/StockFish-1/train') if i.endswith('.jpg')]\n","train_filepaths = [os.path.join('/kaggle/input/fishes-species-in-the-indian-subcontinent/StockFish-1/train/', i) for i in train_filepath]\n","train_label = [i.split('_')[0] for i in train_filepath]\n","for i in range(len(train_filepaths)):\n","    filepaths.append(train_filepaths[i])\n","    labels.append(train_label[i])\n","\n","test_filepath = [i for i in os.listdir('/kaggle/input/fishes-species-in-the-indian-subcontinent/StockFish-1/test') if i.endswith('.jpg')]\n","test_filepaths = [os.path.join('/kaggle/input/fishes-species-in-the-indian-subcontinent/StockFish-1/test/', i) for i in test_filepath]\n","test_label = [i.split('_')[0] for i in test_filepath]\n","for i in range(len(test_filepaths)):\n","    filepaths.append(test_filepaths[i])\n","    labels.append(test_label[i])\n","\n","valid_filepath = [i for i in os.listdir('/kaggle/input/fishes-species-in-the-indian-subcontinent/StockFish-1/valid') if i.endswith('.jpg')]\n","valid_filepaths = [os.path.join('/kaggle/input/fishes-species-in-the-indian-subcontinent/StockFish-1/valid/', i) for i in valid_filepath]\n","valid_label = [i.split('_')[0] for i in valid_filepath]\n","for i in range(len(valid_filepaths)):\n","    filepaths.append(valid_filepaths[i])\n","    labels.append(valid_label[i])\n","\n","\n","df['filepaths'] = filepaths\n","df['labels'] = labels"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-01T02:25:05.612533Z","iopub.status.busy":"2022-09-01T02:25:05.612129Z","iopub.status.idle":"2022-09-01T02:25:05.637152Z","shell.execute_reply":"2022-09-01T02:25:05.635991Z","shell.execute_reply.started":"2022-09-01T02:25:05.6125Z"},"trusted":true},"outputs":[],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-01T02:25:08.391768Z","iopub.status.busy":"2022-09-01T02:25:08.391372Z","iopub.status.idle":"2022-09-01T02:25:08.960856Z","shell.execute_reply":"2022-09-01T02:25:08.959333Z","shell.execute_reply.started":"2022-09-01T02:25:08.391734Z"},"trusted":true},"outputs":[],"source":["def create_data(df):\n","    train_df, dummy_df = train_test_split(df, train_size=.8, shuffle=True, random_state=123, stratify=df['labels'])\n","    valid_df, test_df = train_test_split(dummy_df, train_size=.5, shuffle=True, random_state=123,\n","                                         stratify=dummy_df['labels'])\n","    classes = sorted(train_df['labels'].unique())\n","    class_count = len(classes)\n","    sample_df = train_df.sample(n=50, replace=False)\n","    ht = 0\n","    wt = 0\n","    count = 0\n","    for i in range(len(sample_df)):\n","        fpath = sample_df['filepaths'].iloc[i]\n","        try:\n","            img = cv2.imread(fpath)\n","            h = img.shape[0]\n","            w = img.shape[1]\n","            wt += w\n","            ht += h\n","            count += 1\n","        except:\n","            pass\n","    have = int(ht / count)\n","    wave = int(wt / count)\n","    aspect_ratio = have / wave\n","    print('number of classes in processed dataset= ', class_count)\n","    counts = list(train_df['labels'].value_counts())\n","    print('the maximum files in any class in train_df is ', max(counts),\n","          '  the minimum files in any class in train_df is ', min(counts))\n","    print('train_df length: ', len(train_df), '  test_df length: ', len(test_df), '  valid_df length: ', len(valid_df))\n","    print('average image height= ', have, '  average image width= ', wave, ' aspect ratio h/w= ', aspect_ratio)\n","    \n","    return train_df, test_df, valid_df, classes, class_count\n","\n","train_df, test_df, valid_df, classes, class_count = create_data(df)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-01T02:33:00.777238Z","iopub.status.busy":"2022-09-01T02:33:00.776655Z","iopub.status.idle":"2022-09-01T02:33:00.790583Z","shell.execute_reply":"2022-09-01T02:33:00.789123Z","shell.execute_reply.started":"2022-09-01T02:33:00.777112Z"},"trusted":true},"outputs":[],"source":["epochs = 30\n","batch_size = 32\n","img_size=(300, 300)\n","input_shape = (300, 300, 3)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-01T02:37:44.964316Z","iopub.status.busy":"2022-09-01T02:37:44.963869Z","iopub.status.idle":"2022-09-01T02:37:45.471835Z","shell.execute_reply":"2022-09-01T02:37:45.470149Z","shell.execute_reply.started":"2022-09-01T02:37:44.964282Z"},"trusted":true},"outputs":[],"source":["def make_gens(batch_size, train_df, test_df, valid_df, img_size):\n","    trgen = ImageDataGenerator(horizontal_flip=True)\n","    t_and_v_gen = ImageDataGenerator()\n","    msg = '{0:70s} for train generator'.format(' ')\n","    print(msg, '\\r', end='')  # prints over on the same line\n","    train_ds = trgen.flow_from_dataframe(train_df, x_col='filepaths', y_col='labels',\n","                                         target_size=img_size, class_mode='categorical',\n","                                         color_mode='rgb', batch_size=batch_size, shuffle=True)\n","\n","    msg = '{0:70s} for valid generator'.format(' ')\n","    print(msg, '\\r', end='')  # prints over on the same line\n","    valid_ds = t_and_v_gen.flow_from_dataframe(valid_df, x_col='filepaths', y_col='labels',\n","                                         target_size=img_size, class_mode='categorical',\n","                                         color_mode='rgb', batch_size=batch_size, shuffle=False)\n","\n","    test_len = len(test_df)\n","    test_batch_size = sorted([int(test_len / n) for n in range(1, test_len + 1)\n","                              if test_len % n == 0 and test_len / n<=80], reverse=True)[0]\n","    test_steps = int(test_len / test_batch_size)\n","    msg = '{0:70s} for test generator'.format(' ')\n","    print(msg, '\\r', end='')  # prints over on the same line\n","    test_ds = t_and_v_gen.flow_from_dataframe(test_df, x_col='filepaths', y_col='labels',\n","                                               target_size=img_size, class_mode='categorical',\n","                                               color_mode='rgb', batch_size=batch_size, shuffle=False)\n","\n","    classes = list(train_ds.class_indices.keys())\n","    # class_indices = list(train_ds.class_indices.values())\n","    class_count = len(classes)\n","    # labels = test_ds.labels\n","    print('test batch size: ', test_batch_size, 'test steps: ', test_steps, 'number of classes : ', class_count)\n","\n","    # return train_ds, test_ds, valid_ds, test_batch_size, test_steps, classes\n","\n","    return train_ds, test_ds, valid_ds\n","\n","\n","train_ds, test_ds, valid_ds = make_gens(batch_size, train_df, test_df, valid_df, img_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-01T02:33:06.263361Z","iopub.status.busy":"2022-09-01T02:33:06.262617Z","iopub.status.idle":"2022-09-01T02:33:06.281696Z","shell.execute_reply":"2022-09-01T02:33:06.28046Z","shell.execute_reply.started":"2022-09-01T02:33:06.263324Z"},"trusted":true},"outputs":[],"source":["def GELU(x):\n","    res = 0.5 * x * (1 + tf.nn.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * (x ** 3))))\n","    return res\n","\n","\n","class ResMLPBlock(tf.keras.layers.Layer):\n","    def __init__(self, units, residual_path):\n","        super(ResMLPBlock, self).__init__()\n","        self.residual_path = residual_path\n","        self.D1 = Dense(units, activation='relu')\n","        self.D2 = Dense(units, activation='relu')\n","\n","        if self.residual_path:\n","            self.D3 = Dense(units)\n","            self.D4 = Dense(units)\n","\n","    def call(self, inputs):\n","        residual = inputs\n","\n","        x = self.D1(inputs)\n","        y = self.D2(x)\n","\n","        if self.residual_path:\n","            residual = self.D3(inputs)\n","            residual = GELU(residual)\n","            residual = self.D4(residual)\n","            residual = GELU(residual)\n","\n","        output = y + residual\n","        return output\n","\n","\n","\n","class ResMLP(tf.keras.layers.Layer):\n","    def __init__(self, initial_filters, block_list, num_classes):\n","        super(ResMLP, self).__init__()\n","        self.initial_filters = initial_filters\n","        self.block_list = block_list\n","\n","        self.D1 = Dense(self.initial_filters, activation='relu')\n","        self.B1 = BatchNormalization()\n","\n","        self.blocks = tf.keras.models.Sequential()\n","        for block_id in range(len(block_list)):\n","            for layer_id in range(block_list[block_id]):\n","                if block_id != 0 and layer_id == 0:\n","                    block = ResMLPBlock(units=self.initial_filters, residual_path=True)\n","                else:\n","                    block = ResMLPBlock(units=self.initial_filters, residual_path=False)\n","                self.blocks.add(block)\n","            self.initial_filters *= 2\n","\n","        self.D2 = Dense(num_classes, activation='softmax')\n","\n","\n","    def call(self, inputs):\n","        x = self.D1(inputs)\n","        x = self.B1(x)\n","        x = self.blocks(x)\n","        y = self.D2(x)\n","        return y"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-01T02:33:12.113378Z","iopub.status.busy":"2022-09-01T02:33:12.112136Z","iopub.status.idle":"2022-09-01T02:33:12.130808Z","shell.execute_reply":"2022-09-01T02:33:12.129494Z","shell.execute_reply.started":"2022-09-01T02:33:12.113312Z"},"trusted":true},"outputs":[],"source":["class BottleNeck(tf.keras.layers.Layer):\n","    def __init__(self, filter_num, stride=1):\n","        super(BottleNeck, self).__init__()\n","        self.C1 = Conv2D(filters=filter_num, kernel_size=(1, 1), strides=1, padding='same')\n","        self.B1 = BatchNormalization()\n","        self.A1 = Activation('relu')\n","\n","        self.C2 = Conv2D(filters=filter_num, kernel_size=(3, 3), strides=stride, padding='same')\n","        self.B2 = BatchNormalization()\n","        self.A2 = Activation('relu')\n","\n","        self.C3 = Conv2D(filters=filter_num * 4, kernel_size=(1, 1), strides=1, padding='same')\n","        self.B3 = BatchNormalization()\n","\n","        self.downsample = tf.keras.models.Sequential()\n","        self.downsample.add(Conv2D(filters=filter_num * 4, kernel_size=(1, 1), strides=stride))\n","        self.downsample.add(BatchNormalization())\n","\n","    def call(self, inputs, training=None):\n","        residual = self.downsample(inputs)\n","\n","        x = self.C1(inputs)\n","        x = self.B1(x, training=training)\n","        x = self.A1(x)\n","\n","        x = self.C2(x)\n","        x = self.B2(x, training=training)\n","        x = self.A2(x)\n","\n","        x = self.C3(x)\n","        x = self.B3(x, training=training)\n","        output = tf.nn.relu(tf.keras.layers.add([residual, x]))\n","\n","        return output\n","\n","    \n","def make_bottleneck_layer(filter_num, blocks, stride=1):\n","    res_block = tf.keras.Sequential()\n","    res_block.add(BottleNeck(filter_num, stride=stride))\n","\n","    for _ in range(1, blocks):\n","        res_block.add(BottleNeck(filter_num, stride=1))\n","\n","    return res_block"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-01T02:33:13.485866Z","iopub.status.busy":"2022-09-01T02:33:13.485026Z","iopub.status.idle":"2022-09-01T02:33:13.500769Z","shell.execute_reply":"2022-09-01T02:33:13.499514Z","shell.execute_reply.started":"2022-09-01T02:33:13.485826Z"},"trusted":true},"outputs":[],"source":["class ResNetTypeII(tf.keras.layers.Layer):\n","    def __init__(self, layer_params, input_shape):\n","        super(ResNetTypeII, self).__init__()\n","        assert len(layer_params) == 4, 'The length of layer_params must == 4!!!'\n","\n","        self.C1 = Conv2D(filters=64, kernel_size=(7, 7), strides=2, padding='same', input_shape=input_shape)\n","        self.B1 = BatchNormalization()\n","        self.A1 = Activation('relu')\n","        self.P1 = MaxPooling2D(pool_size=(3, 3), strides=2, padding='same')\n","\n","        self.layer1 = make_bottleneck_layer(filter_num=64,\n","                                             blocks=layer_params[0])\n","        self.layer2 = make_bottleneck_layer(filter_num=128,\n","                                             blocks=layer_params[1],\n","                                             stride=2)\n","        self.layer3 = make_bottleneck_layer(filter_num=256,\n","                                             blocks=layer_params[2],\n","                                             stride=2)\n","        self.layer4 = make_bottleneck_layer(filter_num=512,\n","                                             blocks=layer_params[3],\n","                                             stride=2)\n","        self.P2 = GlobalAveragePooling2D()\n","        # self.D1 = Dense(units=NUM_CLASSES, activation='softmax')\n","\n","    def call(self, inputs, training=None):\n","        x = self.C1(inputs)\n","        x = self.B1(x, training=training)\n","        x = self.A1(x)\n","        x = self.P1(x)\n","\n","        x = self.layer1(x, training=training)\n","        x = self.layer2(x, training=training)\n","        x = self.layer3(x, training=training)\n","        x = self.layer4(x, training=training)\n","        y = self.P2(x)\n","        # y = self.D1(x)\n","\n","        return y"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-01T02:33:15.278407Z","iopub.status.busy":"2022-09-01T02:33:15.277714Z","iopub.status.idle":"2022-09-01T02:33:15.285588Z","shell.execute_reply":"2022-09-01T02:33:15.284393Z","shell.execute_reply.started":"2022-09-01T02:33:15.278372Z"},"trusted":true},"outputs":[],"source":["class NeuralNetWork(tf.keras.Model):\n","    def __init__(self, layer_params, initial_units, block_list, num_classes):\n","        super(NeuralNetWork, self).__init__()\n","\n","        self.layer1 = ResNetTypeII(layer_params=layer_params, input_shape=input_shape)\n","\n","        self.layer2 = ResMLP(initial_filters=initial_units, block_list=block_list, num_classes=num_classes)\n","\n","\n","    def call(self, x):\n","        x = self.layer1(x)\n","        y = self.layer2(x)\n","        return y"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-01T02:38:05.813111Z","iopub.status.busy":"2022-09-01T02:38:05.811412Z","iopub.status.idle":"2022-09-01T02:38:58.119658Z","shell.execute_reply":"2022-09-01T02:38:58.118117Z","shell.execute_reply.started":"2022-09-01T02:38:05.812996Z"},"trusted":true},"outputs":[],"source":["net = NeuralNetWork(layer_params=[3, 4, 6, 3],  initial_units=64, block_list=[2, 2, 2], num_classes=5)\n","\n","net.compile(optimizer='adam',\n","            loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n","            metrics=['categorical_accuracy', 'AUC'])\n","\n","checkpoint_save_path = './Model.ckpt'\n","if os.path.exists(checkpoint_save_path + '.index'):\n","    net.load_weights(checkpoint_save_path)\n","\n","cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path,\n","                                                 save_weights_only=True,\n","                                                 save_best_only=True)\n","\n","history = net.fit(train_ds, epochs=epochs, batch_size=batch_size, callbacks=[cp_callback])\n","\n","net.summary()\n","\n","file = open('./weights.txt', 'w')\n","for v in net.trainable_variables:\n","    file.write(str(v.name) + '\\n')\n","    file.write(str(v.shape) + '\\n')\n","    file.write(str(v.numpy()) + '\\n')\n","\n","file.close()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["acc = history.history['categorical_accuracy']\n","auc = history.history['auc']\n","loss = history.history['loss']\n","\n","\n","plt.figure(figsize=(12, 12))\n","plt.plot(acc, label='Training ACC')\n","plt.plot(auc, label='Training AUC')\n","plt.plot(loss, label='Training LOSS')\n","plt.title('Training ACC AUC LOSS')\n","plt.legend()\n","\n","plt.show()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":2447339,"sourceId":4143666,"sourceType":"datasetVersion"}],"dockerImageVersionId":30235,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"}},"nbformat":4,"nbformat_minor":4}
